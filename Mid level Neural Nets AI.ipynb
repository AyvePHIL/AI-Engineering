{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Engineering fundamentals 2ðŸ”¥\n",
    "## Here, take a deeper dive into neural nets with a focus on the more complex ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # number of inputs\n",
    "num_hidden_layers = 2 # number of hidden layers\n",
    "m = [2, 2] # number of nodes in each hidden layer\n",
    "num_nodes_output = 1 # number of nodes in the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### let us now define the strucutre of ANY neural network more clearly, using the below code\n",
    "##### In order to be able to initialize the weights and the biases to random numbers, we will need to import the Numpy library.\n",
    "###### Effectively , our objective is to be able to initialize the weights and the biases pertianig to any network of any number of hidden layers and numbers of nodes in eac layer. But let us see hwo that works and see how we can make our code re-usable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.16, 0.78]), 'bias': array([0.74])}, 'node_2': {'weights': array([0.41, 0.82]), 'bias': array([0.77])}}, 'layer_2': {'node_1': {'weights': array([0.49, 0.12]), 'bias': array([0.24])}, 'node_2': {'weights': array([0.63, 0.09]), 'bias': array([0.8])}}, 'output': {'node_1': {'weights': array([0.1 , 0.17]), 'bias': array([0.23])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import the Numpy library\n",
    "\n",
    "num_nodes_previous = n # number of nodes in the previous layer\n",
    "\n",
    "network = {} # initialize network an an empty dictionary\n",
    "\n",
    "# loop through each layer and randomly initialize the weights and biases associated with each node\n",
    "# notice how we are adding 1 to the number of hidden layers in order to include the output layer\n",
    "for layer in range(num_hidden_layers + 1): \n",
    "    \n",
    "    # determine name of layer\n",
    "    if layer == num_hidden_layers:\n",
    "        layer_name = 'output'\n",
    "        num_nodes = num_nodes_output\n",
    "    else:\n",
    "        layer_name = 'layer_{}'.format(layer + 1)\n",
    "        num_nodes = m[layer]\n",
    "    \n",
    "    # initialize weights and biases associated with each node in the current layer\n",
    "    network[layer_name] = {}\n",
    "    for node in range(num_nodes):\n",
    "        node_name = 'node_{}'.format(node+1)\n",
    "        network[layer_name][node_name] = {\n",
    "            'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "            'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "        }\n",
    "    \n",
    "    num_nodes_previous = num_nodes\n",
    "    \n",
    "print(network) # print network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output):\n",
    "    \n",
    "    num_nodes_previous = num_inputs # number of nodes in the previous layer\n",
    "\n",
    "    network = {}\n",
    "    \n",
    "    # loop through each layer and randomly initialize the weights and biases associated with each layer\n",
    "    for layer in range(num_hidden_layers + 1):\n",
    "        \n",
    "        if layer == num_hidden_layers:\n",
    "            layer_name = 'output' # name last layer in the network output\n",
    "            num_nodes = num_nodes_output\n",
    "        else:\n",
    "            layer_name = 'layer_{}'.format(layer + 1) # otherwise give the layer a number\n",
    "            num_nodes = num_nodes_hidden[layer] \n",
    "        \n",
    "        # initialize weights and bias for each node\n",
    "        network[layer_name] = {}\n",
    "        for node in range(num_nodes):\n",
    "            node_name = 'node_{}'.format(node+1)\n",
    "            network[layer_name][node_name] = {\n",
    "                'weights': np.around(np.random.uniform(size=num_nodes_previous), decimals=2),\n",
    "                'bias': np.around(np.random.uniform(size=1), decimals=2),\n",
    "            }\n",
    "    \n",
    "        num_nodes_previous = num_nodes\n",
    "\n",
    "    return network # return the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the above, we initialize_netwrok function but now let us create a netwrok that can:\n",
    "1. Take 5 inputs\n",
    "2. Has 3 hidden layers\n",
    "3. Has 3 nodes in the first layer, 2 nodes in the 2nd layer, and 3 nodes in the third layer\n",
    "4. Has 1 node in the output layer\n",
    "##### We will call this network, small_network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_1': {'node_1': {'weights': array([0.48, 0.72, 0.04, 0.4 , 0.09]), 'bias': array([0.14])}, 'node_2': {'weights': array([0.38, 0.42, 0.49, 0.89, 0.92]), 'bias': array([0.8])}, 'node_3': {'weights': array([0.93, 0.74, 0.84, 0.71, 0.13]), 'bias': array([0.44])}}, 'layer_2': {'node_1': {'weights': array([0.34, 1.  , 0.88]), 'bias': array([0.08])}, 'node_2': {'weights': array([0.43, 0.52, 0.96]), 'bias': array([0.67])}}, 'layer_3': {'node_1': {'weights': array([0.79, 0.21]), 'bias': array([0.84])}, 'node_2': {'weights': array([0.05, 0.28]), 'bias': array([0.99])}, 'node_3': {'weights': array([0.2 , 0.39]), 'bias': array([0.3])}}, 'output': {'node_1': {'weights': array([0.2 , 0.41, 0.39]), 'bias': array([0.54])}}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the network parameters\n",
    "num_inputs = 5\n",
    "num_hidden_layers = 3\n",
    "num_nodes_hidden = [3, 2, 3]  # Number of nodes in each hidden layer\n",
    "num_nodes_output = 1\n",
    "\n",
    "# Create the network using the initialize_network function\n",
    "small_network = initialize_network(num_inputs, num_hidden_layers, num_nodes_hidden, num_nodes_output)\n",
    "\n",
    "print(small_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2\n",
    "\n",
    "### Let us compute the weighted sum at each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weighted_sum(inputs, weights, bias):\n",
    "    return np.sum(inputs * weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs to the network are [0.15 0.74 0.26 0.53 0.01]\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 inputs that we can fee to small_network,\n",
    "from random import seed\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(12)\n",
    "inputs = np.around(np.random.uniform(size=5), decimals=2)\n",
    "\n",
    "print('The inputs to the network are {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum at the first node in the first hidden layer is: [0.9681]\n"
     ]
    }
   ],
   "source": [
    "## Let us now compute the weighed sum\n",
    "\n",
    "# Extract the weights and bias for the first node in the first hidden layer\n",
    "weights = small_network['layer_1']['node_1']['weights']\n",
    "bias = small_network['layer_1']['node_1']['bias']\n",
    "\n",
    "# Compute the weighted sum\n",
    "weighted_sum = compute_weighted_sum(inputs, weights, bias)\n",
    "\n",
    "print(\"The weighted sum at the first node in the first hidden layer is:\", weighted_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3\n",
    "### We now copmute the node action (or activation function in full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each node is simply a non-linear tranformation of the weighted sum. We use activation functions for this mapping. Let's use the sigmoid function as the activation function here. \n",
    "#So let's define a function that takes a weighted sum as input and returns the non-linear transformation of the input using the sigmoid function.\n",
    "\n",
    "def node_activation(weighted_sum):\n",
    "    return 1.0 / (1.0 + np.exp(-1 * weighted_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output of the first node in the first hidden layer is: [0.72474063]\n"
     ]
    }
   ],
   "source": [
    "# To compute the output of the first node in the first hidden layer, we will need to use the node_activation function with the calculated weighted sum from the previous step.\n",
    "\n",
    "# Compute the node activation\n",
    "node_output = node_activation(weighted_sum)\n",
    "\n",
    "print(\"The output of the first node in the first hidden layer is:\", node_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "##### The final piece of building a neural network that can perform predictions is to put everything together. So let's create a function that applies the compute_weighted_sum and node_activation functions to each node in the network and propagates the data all the way to the output layer and outputs a prediction for each node in the output layer.%%Exciting ðŸ™‚%%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### METHODOLOGY in achieving the above\n",
    "1. Start with the input layer as the input to the first hidden layer.\n",
    "2. Compute the weighted sum at the nodes of the current layer.\n",
    "3. Compute the output of the nodes of the current layer.\n",
    "4. Set the output of the current layer to be the input to the next layer.\n",
    "5. Move to the next layer in the network.\n",
    "6. Repeat steps 2 - 4 until we compute the output of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, inputs):\n",
    "    \n",
    "    layer_inputs = list(inputs) # start with the input layer as the input to the first hidden layer\n",
    "    \n",
    "    for layer in network:\n",
    "        \n",
    "        layer_data = network[layer]\n",
    "        \n",
    "        layer_outputs = [] \n",
    "        for layer_node in layer_data:\n",
    "        \n",
    "            node_data = layer_data[layer_node]\n",
    "        \n",
    "            # compute the weighted sum and the output of each node at the same time \n",
    "            node_output = node_activation(compute_weighted_sum(layer_inputs, node_data['weights'], node_data['bias']))\n",
    "            layer_outputs.append(np.around(node_output[0], decimals=4))\n",
    "            \n",
    "        if layer != 'output':\n",
    "            print('The outputs of the nodes in hidden layer number {} is {}'.format(layer.split('_')[1], layer_outputs))\n",
    "    \n",
    "        layer_inputs = layer_outputs # set the output of this layer to be the input to next layer\n",
    "\n",
    "    network_predictions = layer_outputs\n",
    "    return network_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The outputs of the nodes in hidden layer number 1 is [0.7247, 0.8552, 0.8485]\n",
      "The outputs of the nodes in hidden layer number 2 is [0.8731, 0.9039]\n",
      "The outputs of the nodes in hidden layer number 3 is [0.8481, 0.7836, 0.6958]\n",
      "The prediction of the small network is: [0.7862]\n"
     ]
    }
   ],
   "source": [
    "# Now, using the forward_propagate function to compute the prediction of our small network, we get the following\n",
    "\n",
    "# Make a prediction using the small_network\n",
    "prediction = forward_propagate(small_network, inputs)\n",
    "\n",
    "print(\"The prediction of the small network is:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Obviously, the above gave us a bit of a glimpse into what potentially lies ahead of this AI engineering journey indeed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
