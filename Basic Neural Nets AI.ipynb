{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Engineering fundamentals ðŸ”¥\n",
    "## Here, we try and understand a basic neural network with two inputs, two neuron of the first and only hidden layer, and the output node or output screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cocl.us/general_neural_network\" alt=\"Neural Network General\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1\n",
    "#### Obtain the Sigmoid Function as our activation function in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13 0.55 0.3 ]\n",
      "[0.67 0.69 0.69 0.48 0.74 0.55]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # import Numpy library to generate \n",
    "\n",
    "weights = np.around(np.random.uniform(size=6), decimals=2) # initialize the weights\n",
    "biases = np.around(np.random.uniform(size=3), decimals=2) # initialize the biases\n",
    "\n",
    "print(biases)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 is 0.5 and x2 is 0.85\n"
     ]
    }
   ],
   "source": [
    "#Now we have our weights and bisases defined for our neural network, let us compute the ouput for a given input x_1 and x_2\n",
    "x_1 = 0.5 # input 1\n",
    "x_2 = 0.85 # input 2\n",
    "\n",
    "print('x1 is {} and x2 is {}'.format(x_1, x_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0514999999999999\n"
     ]
    }
   ],
   "source": [
    "# Now let us grab the wieghted sum of the inputs, z11, at the first node of the first and only hidden layer\n",
    "z11 = x_1*weights[0]+x_2*weights[1]+biases[0]\n",
    "print(z11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.303\n"
     ]
    }
   ],
   "source": [
    "# Now let us grab the wieghted sum of the inputs, z11, at the second node of the first and only hidden layer\n",
    "z12 = x_1*weights[2]+x_2*weights[3]+biases[1]\n",
    "print(z12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.303\n"
     ]
    }
   ],
   "source": [
    "#Now let us try and print the weighted sum\n",
    "weighted_sum = z12\n",
    "print(weighted_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the first node in the hidden layer is 0.7411\n"
     ]
    }
   ],
   "source": [
    "#Now let us get the sigmoid of the first node in the hidden layer, as a_11\n",
    "a_11 = 1.0 / (1.0 + np.exp(-z11))\n",
    "\n",
    "print('The activation of the first node in the hidden layer is {}'.format(np.around(a_11, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activation of the second node in the hidden layer is 0.7863\n"
     ]
    }
   ],
   "source": [
    "# Now let us do the same for z_12, of the second node in the hidden layer\n",
    "a_12 = 1.0 / (1.0 + np.exp(-z12))\n",
    "\n",
    "print('The activation of the second node in the hidden layer is {}'.format(np.around(a_12, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the ouput now is 1.2809\n"
     ]
    }
   ],
   "source": [
    " #So, let's compute the weighted sum of these inputs to the node in the output layer. Assigning the value z_2 to it\n",
    "z_2 = a_11 * weights[4] + a_12 * weights[5] + biases[2]\n",
    "print('The weighted sum of the ouput now is {}'.format(np.around(z_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted sum of the output of the network now is 0.7826\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's compute the output of the network as the activation of the node in the output layer ðŸ™‚\n",
    "a_2 = 1.0 / (1.0 + np.exp(-z_2))\n",
    "print('The weighted sum of the output of the network now is {}'.format(np.around(a_2, decimals=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### Obviously, the above is certainly childs play for real-world and real-life problems, but that conlcudes this itnroductory neural net lesson.\n",
    "#### We shall now dive deeper into the more complex approaches in the next project bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
